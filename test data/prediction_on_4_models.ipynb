{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2ed4df-1e98-475c-aee9-c1ef6b270a90",
   "metadata": {},
   "source": [
    "Covert student excel and save all dialogues in json："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83b89c86-d948-44bf-a7e8-5d24895a5eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed 85 unique dialogues and saved to all_dialogues.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "\n",
    "def find_matching_column(columns, keyword):\n",
    "    for col in columns:\n",
    "        if keyword.lower() in col.lower():\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def parse_dialogue(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return []\n",
    "\n",
    "    turns = []\n",
    "    # 使用正则切割每个发言段，避免截断内容\n",
    "    segments = re.split(r'\\n*(?=(C|P):)', text.strip())\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(segments) - 1:\n",
    "        if segments[i] in ['C', 'P']:\n",
    "            speaker_code = segments[i]\n",
    "            content = segments[i + 1].lstrip(':').strip()\n",
    "            role = \"assistant\" if speaker_code == \"C\" else \"user\"\n",
    "            speaker = \"doctor\" if speaker_code == \"C\" else \"patient\"\n",
    "            turns.append({\n",
    "                \"role\": role,\n",
    "                \"speaker\": speaker,\n",
    "                \"content\": f\"** {content}\"\n",
    "            })\n",
    "            i += 2\n",
    "        else:\n",
    "            i += 1\n",
    "    return turns\n",
    "\n",
    "# Batch process files in a folder\n",
    "input_folder = \"test\"\n",
    "output_file = \"all_dialogues.json\"\n",
    "all_dialogues = []\n",
    "seen_dialogues = set()  # To track unique dialogues\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".csv\") or filename.endswith(\".tsv\"):\n",
    "        filepath = os.path.join(input_folder, filename)\n",
    "        sep = \"\\t\" if filename.endswith(\".tsv\") else \",\"\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                filepath,\n",
    "                sep=sep,\n",
    "                encoding='utf-8',\n",
    "                quotechar='\"',\n",
    "                doublequote=True,\n",
    "                escapechar=\"\\\\\",\n",
    "                on_bad_lines='skip',\n",
    "                engine=\"python\"\n",
    "            ).fillna(\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed to load {filename}: {e}\")\n",
    "            continue\n",
    "\n",
    "        df.columns = [col.strip() for col in df.columns]\n",
    "        col_basic = find_matching_column(df.columns, \"basic conversation\")\n",
    "        col_physical = find_matching_column(df.columns, \"physical function\")\n",
    "        col_emotional = find_matching_column(df.columns, \"emotional feedback\")\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            basic = parse_dialogue(row.get(col_basic, \"\"))\n",
    "            physical = parse_dialogue(row.get(col_physical, \"\"))\n",
    "            emotional = parse_dialogue(row.get(col_emotional, \"\"))\n",
    "            full = basic + physical + emotional\n",
    "\n",
    "            if full:\n",
    "                dialogue_str = json.dumps(full, ensure_ascii=False, sort_keys=True)\n",
    "                if dialogue_str not in seen_dialogues:\n",
    "                    all_dialogues.append(full)\n",
    "                    seen_dialogues.add(dialogue_str)\n",
    "\n",
    "# Save all unique dialogues\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_dialogues, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Processed {len(all_dialogues)} unique dialogues and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8d600-ad4d-4554-bd09-8a4b869e1f8f",
   "metadata": {},
   "source": [
    "Convert all test dialogues into input format(0shot) for Qwen3-fine-tuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22f236e-7fb3-4780-9fbb-5ac020183ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === 文件路径设置 ===\n",
    "input_file = \"all_dialogues.json\"\n",
    "json_output_file = \"test_inputs_for_model_fixed.json\"\n",
    "txt_output_file = \"test_inputs_for_model_chatml_fixed.txt\"\n",
    "\n",
    "# === Markdown 清理函数 ===\n",
    "def clean_markdown(text):\n",
    "    return re.sub(r'^\\*+\\s*', '', text.strip())\n",
    "\n",
    "# === ChatML 文本格式转换（调试查看用）===\n",
    "def convert_to_chatml(system_prompt, turns):\n",
    "    lines = [f\"<|im_start|>system\\n{system_prompt}\\n<|im_end|>\"]\n",
    "    for turn in turns:\n",
    "        role = \"user\" if turn[\"speaker\"] == \"patient\" else \"assistant\"\n",
    "        content = clean_markdown(turn[\"content\"])\n",
    "        lines.append(f\"<|im_start|>{role}\\n{content}\\n<|im_end|>\")\n",
    "    lines.append(\"<|im_start|>assistant\\n\")  # 生成从此开始\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# === OpenAI 风格 messages 构建 ===\n",
    "def convert_to_messages(system_prompt, turns):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    for turn in turns:\n",
    "        role = \"user\" if turn[\"speaker\"] == \"patient\" else \"assistant\"\n",
    "        content = clean_markdown(turn[\"content\"])\n",
    "        messages.append({\"role\": role, \"content\": content})\n",
    "    return messages\n",
    "\n",
    "# === System prompt ===\n",
    "system_prompt = (\n",
    "    \"You are an attentive and empathetic clinician engaging in a mobility-focused consultation. \"\n",
    "    \"The conversation pertains to one of the following ICF categories: \"\n",
    "    \"D420 (Transferring Oneself), D445 (Hand and Arm Use), D465 (Moving Around Using Equipment), \"\n",
    "    \"and D470 (Using Transportation). \"\n",
    "    \"Based on the patient's previous response, generate a clinically appropriate follow-up question \"\n",
    "    \"that helps clarify functional limitations or explore emotional and contextual factors. \"\n",
    "    \"The question should be relevant, concise, and aligned with clinical reasoning. /no_think.\"\n",
    ")\n",
    "\n",
    "# === 加载数据 ===\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    dialogues = json.load(f)\n",
    "\n",
    "generation_inputs = []\n",
    "chatml_blocks = []\n",
    "\n",
    "for i, dialogue in tqdm(enumerate(dialogues), total=len(dialogues), desc=\"Generating test prompts\"):\n",
    "    dialogue_id = i + 1\n",
    "    doctor_indices = [idx for idx, turn in enumerate(dialogue) if turn.get(\"speaker\") == \"doctor\"]\n",
    "\n",
    "    for doc_turn_idx in doctor_indices[1:]:\n",
    "        prefix_turns = dialogue[:doc_turn_idx]\n",
    "        if not prefix_turns:\n",
    "            continue\n",
    "\n",
    "        # 结构化输出\n",
    "        messages = convert_to_messages(system_prompt, prefix_turns)\n",
    "\n",
    "        generation_inputs.append({\n",
    "            \"dialogue_id\": dialogue_id,\n",
    "            \"turn_index\": doc_turn_idx,\n",
    "            \"messages\": messages\n",
    "        })\n",
    "\n",
    "        # ChatML 展示文本\n",
    "        chatml = convert_to_chatml(system_prompt, prefix_turns)\n",
    "        chatml_blocks.append(chatml)\n",
    "\n",
    "# === 保存 JSON 用于推理 ===\n",
    "with open(json_output_file, \"w\", encoding=\"utf-8\") as f_json:\n",
    "    json.dump(generation_inputs, f_json, ensure_ascii=False, indent=2)\n",
    "\n",
    "# === 保存纯文本 ChatML 用于人工检查 ===\n",
    "with open(txt_output_file, \"w\", encoding=\"utf-8\") as f_txt:\n",
    "    f_txt.write(\"\\n\\n\".join(chatml_blocks))\n",
    "\n",
    "print(f\"✅ JSON file saved to: {json_output_file}\")\n",
    "print(f\"✅ ChatML .txt file saved to: {txt_output_file}\")\n",
    "print(f\"✅ Total test prompts: {len(generation_inputs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71163cad-0f2b-4147-9b20-23e44077b920",
   "metadata": {},
   "source": [
    "Test with json format as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd50f09e-0066-4069-be63-973e1b86548f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|███████████████████████████| 730/730 [1:57:35<00:00,  9.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved to finetuned_qwen3_0shout_test_output.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# Local OpenAI API proxy address\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"cltl\"  # Replace with your actual key if needed\n",
    ")\n",
    "\n",
    "# Input/output paths\n",
    "input_path = \"test_inputs_for_model_fixed.json\"\n",
    "output_path = \"finetuned_qwen3_0shout_test_output.json\"\n",
    "model_name = \"Qwen3_8B_Merged-8.2B-Q8_0.gguf\"\n",
    " # Fill in according to your deployed model name\n",
    "\n",
    "# 读取测试数据\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "results = []\n",
    "for item in tqdm(test_data, desc=\"Generating\"):\n",
    "    messages = item[\"messages\"]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=256\n",
    "        )\n",
    "        item[\"generated_followup\"] = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        item[\"generated_followup\"] = f\"[ERROR] {str(e)}\"\n",
    "\n",
    "    results.append(item)\n",
    "\n",
    "# 保存结果\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    json.dump(results, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Output saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3d81c-b739-4cda-a6cf-8856f6c6da5f",
   "metadata": {},
   "source": [
    "Test with ChatML as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68b39661-1e43-4dc0-896a-cec2b89e9231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|███████████████████████████| 730/730 [2:02:18<00:00, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved to 3finetuned_qwen3_chatml_test_output.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# Local OpenAI API proxy address\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"cltl\"  # Replace if needed\n",
    ")\n",
    "\n",
    "# 文件路径\n",
    "input_path = \"test_inputs_for_model_chatml_fixed.txt\"\n",
    "output_path = \"3finetuned_qwen3_chatml_test_output.json\"\n",
    "model_name = \"Qwen3_8B_Merged-8.2B-Q8_0.gguf\"\n",
    "\n",
    "# 读取 ChatML 测试数据（每个 prompt 之间是 \\n\\n 分隔）\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    blocks = f.read().strip().split(\"\\n\\n\")\n",
    "\n",
    "results = []\n",
    "for i, prompt_text in enumerate(tqdm(blocks, desc=\"Generating\")):\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=model_name,\n",
    "            prompt=prompt_text,\n",
    "            temperature=0.7,\n",
    "            max_tokens=256,\n",
    "        )\n",
    "        result = {\n",
    "            \"id\": i + 1,\n",
    "            \"chatml_prompt\": prompt_text,\n",
    "            \"generated_followup\": response.choices[0].text.strip()  # ✅ 修复这里\n",
    "        }\n",
    "    except Exception as e:\n",
    "        result = {\n",
    "            \"id\": i + 1,\n",
    "            \"chatml_prompt\": prompt_text,\n",
    "            \"generated_followup\": f\"[ERROR] {str(e)}\"\n",
    "        }\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "# 保存结果\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    json.dump(results, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Output saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4bf20f-d2f9-4af7-bab1-b5db5d5a5e47",
   "metadata": {},
   "source": [
    "Convert all test dialogues into input format(few shot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ee3d41bb-798f-40f0-a632-f46da17bd684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating few-shot prompts: 100%|████████████| 85/85 [00:00<00:00, 2438.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ChatML saved to: test_inputs_with_fewshot_chatml.txt\n",
      "✅ JSON saved to: test_inputs_with_fewshot.json\n",
      "✅ Total prompts: 730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === 文件路径设置 ===\n",
    "input_file = \"all_dialogues.json\"\n",
    "output_txt_file = \"test_inputs_with_fewshot_chatml.txt\"\n",
    "output_json_file = \"test_inputs_with_fewshot.json\"\n",
    "\n",
    "# === 示例对话（few-shot） ===\n",
    "example1 = [\n",
    "    {\"role\": \"assistant\", \"content\": \"C: Hi, how are you doing today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: I'm doing pretty well. I walked my dog to the park this morning, and we played for a bit.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That sounds lovely! What's your dog’s name?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: His name is Timo.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: Timo—what a great name! What did you two play?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: We played frisbee fetch. It was fun.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That’s good to hear. Sounds like your arms are feeling better lately.\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Yeah, I’m really able to throw the frisbee now, which is great.\"},\n",
    "\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That’s encouraging. Did you feel any discomfort when throwing the frisbee?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Just a little. After a few throws, my shoulder felt a bit sore, but nothing like before.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: Did you notice any limitation in your range of motion when reaching back to throw?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: A little when I raised my arm overhead. It's not painful, but it feels a bit tight.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: I see. How about twisting your arm—for example, opening bottles or turning door handles?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Doorknobs are fine, but opening bottles is still a bit hard. My wrist doesn’t feel very strong.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: Got it. What about carrying things like shopping bags or pouring from a kettle?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Heavier stuff is still a challenge. I had some trouble lifting a full kettle yesterday.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: And how about reaching into high cabinets or stretching your arm out to grab things?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: If I reach too far, especially upward, I feel a pulling near my elbow. So I try not to overdo it.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That’s wise. Are there daily activities you’ve had to adapt or take slower?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Folding laundry takes longer. Lifting and twisting both arms just wears me out faster.\"},\n",
    "\n",
    "    {\"role\": \"assistant\", \"content\": \"C: How do you feel about the progress you’ve made so far?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Honestly, it’s a relief. A few weeks ago I couldn’t even lift a mug comfortably, so this feels like a big win.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That’s great to hear. Do you ever feel discouraged on harder days?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Yeah, definitely. Some days my arms feel weaker, and I start worrying that I might be slipping backwards.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That’s totally understandable. Have you found anything that helps you stay motivated when that happens?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: I try to focus on small wins, like managing the laundry or playing with Timo. It reminds me that I’m getting stronger.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That’s a great approach. And it sounds like Timo is good at keeping your spirits up.\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: He really is. He keeps me moving—and smiling.\"}\n",
    "]\n",
    "example2 = [\n",
    "    {\"role\": \"assistant\", \"content\": \"C: Hi there! Before we get started, could I have your name and age, please?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: My name is Voila. I’m 70 years old.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: No way! You don’t look 70.\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Aw, thank you! That’s so sweet of you to say.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: You're very welcome. Now, how can I help you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Well, my walker isn’t really working for me anymore.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: I see. Do you want to get a new one, or are you thinking of trying something else?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Actually, I think I might need a wheelchair now.\"},\n",
    "\n",
    "    {\"role\": \"assistant\", \"content\": \"C: I'm sorry to hear that. I know it can be tough. How have you been managing with the walker so far?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: It’s been okay, but lately I’ve needed more support, especially when I’m outside or walking longer distances.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: What kind of surfaces are most challenging with the walker—like uneven ground, slopes, or indoors?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Pavement with cracks and any uphill sections are really hard. Indoors is a bit easier, but carpets can make the wheels stick.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That makes sense. Do you ever find yourself getting stuck or needing to stop and rest?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Yes, quite often. I get tired halfway through my block, and my hands start to ache from gripping the handles.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: Have you tried using any other mobility devices before—like a rollator with a seat or a powered wheelchair?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: I’ve used a rollator once during rehab, but it was still hard to push. I haven’t tried powered devices yet.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: What about turning or navigating tight spaces? Has that become more difficult recently?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Definitely. I used to be able to make sharp turns in the hallway, but now I bump into the wall or have to back up and try again.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: And when you go out—like to the grocery store—do you feel comfortable using the walker, or do you hesitate?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: I’ve started avoiding longer outings unless someone’s with me. I just don’t trust myself to get through them anymore.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That’s completely understandable. Based on what you’re describing, a self-propelled or even lightweight wheelchair might offer more stability and less strain.\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: I’ve been thinking the same. I want more freedom to move around, not less.\"},\n",
    "\n",
    "    {\"role\": \"assistant\", \"content\": \"C: How are you feeling about needing to make that switch to a wheelchair?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Honestly, it’s a little overwhelming. I do not like the fact that I need a wheelchair.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That’s a really common feeling. But a lot of people find the right equipment actually helps them feel more in control and confident.\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: I hope so. I’m just afraid it’ll make people see me differently, like I’m fragile.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: I hear you. But using the right tool for your needs doesn’t change who you are—it just helps you move through life more safely.\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Yeah, I guess that’s true.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: Do you have support around you for this transition—family, friends, maybe someone who could help you test out different options?\"},\n",
    "    {\"role\": \"user\", \"content\": \"P: Yes, I have two daughters. They’ve been very encouraging.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"C: That’s wonderful to hear. You’re not alone in this, and we’ll work together to find the setup that best supports your independence.\"}\n",
    "]\n",
    "\n",
    "# === System prompt ===\n",
    "system_prompt = (\n",
    "    \"You are an attentive and empathetic clinician engaging in a mobility-focused consultation. \"\n",
    "    \"The conversation pertains to one of the following ICF categories: \"\n",
    "    \"D420 (Transferring Oneself), D445 (Hand and Arm Use), D465 (Moving Around Using Equipment), \"\n",
    "    \"and D470 (Using Transportation). \"\n",
    "    \"Below are two example conversations between clinician (C) and patient (P). Use them as reference for tone and structure.\"\n",
    "    \"Then you will see a real consultation. Based on the patient's previous response, generate a clinically appropriate follow-up question \"\n",
    "    \"that helps clarify functional limitations or explore emotional and contextual factors.\"\n",
    "    \"The question should be relevant, concise, and aligned with clinical reasoning.\"\n",
    "    \"/no_think\"\n",
    ")\n",
    "\n",
    "# === Markdown 清理函数 ===\n",
    "def clean_markdown(text):\n",
    "    return re.sub(r'^\\*+\\s*', '', text.strip())\n",
    "\n",
    "# === ChatML 文本格式构建 ===\n",
    "def build_chatml(system_prompt, fewshot_turns, real_turns):\n",
    "    lines = [f\"<|im_start|>system\\n{system_prompt}\\n<|im_end|>\"]\n",
    "    lines.append(\"<|im_start|>system\\nExample 1:\\n<|im_end|>\")\n",
    "    for turn in fewshot_turns[0]:\n",
    "        role = \"user\" if turn[\"role\"] == \"user\" else \"assistant\"\n",
    "        lines.append(f\"<|im_start|>{role}\\n{clean_markdown(turn['content'])}\\n<|im_end|>\")\n",
    "    lines.append(\"<|im_start|>system\\nExample 2:\\n<|im_end|>\")\n",
    "    for turn in fewshot_turns[1]:\n",
    "        role = \"user\" if turn[\"role\"] == \"user\" else \"assistant\"\n",
    "        lines.append(f\"<|im_start|>{role}\\n{clean_markdown(turn['content'])}\\n<|im_end|>\")\n",
    "    lines.append(\"<|im_start|>system\\nNow here is the real consultation:\\n<|im_end|>\")\n",
    "    for turn in real_turns:\n",
    "        role = \"user\" if turn[\"speaker\"] == \"patient\" else \"assistant\"\n",
    "        lines.append(f\"<|im_start|>{role}\\n{clean_markdown(turn['content'])}\\n<|im_end|>\")\n",
    "    lines.append(\"<|im_start|>assistant\\n\")  # 模型从此开始生成\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# === OpenAI 风格结构化格式 ===\n",
    "def build_messages(system_prompt, fewshot_turns, real_turns):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    messages.append({\"role\": \"system\", \"content\": \"Example 1:\"})\n",
    "    messages.extend(fewshot_turns[0])\n",
    "    messages.append({\"role\": \"system\", \"content\": \"Example 2:\"})\n",
    "    messages.extend(fewshot_turns[1])\n",
    "    messages.append({\"role\": \"system\", \"content\": \"Now here is the real consultation:\"})\n",
    "    for turn in real_turns:\n",
    "        role = \"user\" if turn[\"speaker\"] == \"patient\" else \"assistant\"\n",
    "        messages.append({\"role\": role, \"content\": clean_markdown(turn[\"content\"])})\n",
    "    return messages\n",
    "\n",
    "# === 加载数据 ===\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    dialogues = json.load(f)\n",
    "\n",
    "chatml_blocks = []\n",
    "json_blocks = []\n",
    "\n",
    "for i, dialogue in tqdm(enumerate(dialogues), total=len(dialogues), desc=\"Generating few-shot prompts\"):\n",
    "    dialogue_id = i + 1\n",
    "    doctor_indices = [idx for idx, turn in enumerate(dialogue) if turn.get(\"speaker\") == \"doctor\"]\n",
    "\n",
    "    for doc_turn_idx in doctor_indices[1:]:  # 从第二次医生发言开始\n",
    "        prefix_turns = dialogue[:doc_turn_idx]\n",
    "        if not prefix_turns:\n",
    "            continue\n",
    "\n",
    "        chatml_text = build_chatml(system_prompt, [example1, example2], prefix_turns)\n",
    "        json_structured = {\n",
    "            \"dialogue_id\": dialogue_id,\n",
    "            \"turn_index\": doc_turn_idx,\n",
    "            \"messages\": build_messages(system_prompt, [example1, example2], prefix_turns)\n",
    "        }\n",
    "\n",
    "        chatml_blocks.append(chatml_text)\n",
    "        json_blocks.append(json_structured)\n",
    "\n",
    "# === 保存 ChatML 和 JSON ===\n",
    "with open(output_txt_file, \"w\", encoding=\"utf-8\") as f_txt:\n",
    "    f_txt.write(\"\\n\\n\".join(chatml_blocks))\n",
    "\n",
    "with open(output_json_file, \"w\", encoding=\"utf-8\") as f_json:\n",
    "    json.dump(json_blocks, f_json, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ ChatML saved to: {output_txt_file}\")\n",
    "print(f\"✅ JSON saved to: {output_json_file}\")\n",
    "print(f\"✅ Total prompts: {len(chatml_blocks)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d07d2d-3cde-42de-9eaa-84edd93f8ee0",
   "metadata": {},
   "source": [
    "test with ChatML format as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e343e5-26f2-497e-9d96-c0e0d8687718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# Local OpenAI API proxy address\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"cltl\"  # Replace if needed\n",
    ")\n",
    "\n",
    "# 文件路径\n",
    "input_path = \"test_inputs_with_fewshot_chatml.txt\"\n",
    "output_path = \"fewshot_finetuned_qwen3_output.json\"\n",
    "model_name = \"Qwen3_8B_Merged-8.2B-Q8_0.gguf\"\n",
    "\n",
    "# 读取 ChatML 测试数据（每个 prompt 之间是 \\n\\n 分隔）\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    blocks = f.read().strip().split(\"\\n\\n\")\n",
    "\n",
    "results = []\n",
    "for i, prompt_text in enumerate(tqdm(blocks, desc=\"Generating\")):\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=model_name,\n",
    "            prompt=prompt_text,\n",
    "            temperature=0.7,\n",
    "            max_tokens=256,\n",
    "        )\n",
    "        result = {\n",
    "            \"id\": i + 1,\n",
    "            \"chatml_prompt\": prompt_text,\n",
    "            \"generated_followup\": response.choices[0].text.strip()  # ✅ 修复这里\n",
    "        }\n",
    "    except Exception as e:\n",
    "        result = {\n",
    "            \"id\": i + 1,\n",
    "            \"chatml_prompt\": prompt_text,\n",
    "            \"generated_followup\": f\"[ERROR] {str(e)}\"\n",
    "        }\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "# 保存结果\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    json.dump(results, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Output saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a404b630-071c-4de2-a51a-c1d0fde6594d",
   "metadata": {},
   "source": [
    "改了一个例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c5925b-5200-4c5a-95d8-82e3c8ae1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# Local OpenAI API proxy address\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"cltl\"  # Replace if needed\n",
    ")\n",
    "\n",
    "# 文件路径\n",
    "input_path = \"test_inputs_with_fewshot_chatml.txt\"\n",
    "output_path = \"fewshot_finetuned_qwen3_chatml_test_output.json\"\n",
    "model_name = \"Qwen3_8B_Merged-8.2B-Q8_0.gguf\"\n",
    "\n",
    "# 读取 ChatML 测试数据（每个 prompt 之间是 \\n\\n 分隔）\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    blocks = f.read().strip().split(\"\\n\\n\")\n",
    "\n",
    "results = []\n",
    "for i, prompt_text in enumerate(tqdm(blocks, desc=\"Generating\")):\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=model_name,\n",
    "            prompt=prompt_text,\n",
    "            temperature=0.7,\n",
    "            max_tokens=256,\n",
    "        )\n",
    "        result = {\n",
    "            \"id\": i + 1,\n",
    "            \"chatml_prompt\": prompt_text,\n",
    "            \"generated_followup\": response.choices[0].text.strip()  # ✅ 修复这里\n",
    "        }\n",
    "    except Exception as e:\n",
    "        result = {\n",
    "            \"id\": i + 1,\n",
    "            \"chatml_prompt\": prompt_text,\n",
    "            \"generated_followup\": f\"[ERROR] {str(e)}\"\n",
    "        }\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "# 保存结果\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    json.dump(results, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Output saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dfac3f-36d0-46e9-b54c-9daac93cf1e5",
   "metadata": {},
   "source": [
    "再试一遍："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4d0b780-7436-4367-bb45-ec638152024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|███████████████████████████| 730/730 [1:45:15<00:00,  8.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Output saved to 22fewshot_finetuned_qwen3_chatml_test_output.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# Local OpenAI API proxy address\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8000/v1\",\n",
    "    api_key=\"cltl\"  # Replace if needed\n",
    ")\n",
    "\n",
    "# 文件路径\n",
    "input_path = \"test_inputs_with_fewshot_chatml.txt\"\n",
    "output_path = \"22fewshot_finetuned_qwen3_chatml_test_output.json\"\n",
    "model_name = \"Qwen3_8B_Merged-8.2B-Q8_0.gguf\"\n",
    "\n",
    "# 读取 ChatML 测试数据（每个 prompt 之间是 \\n\\n 分隔）\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    blocks = f.read().strip().split(\"\\n\\n\")\n",
    "\n",
    "results = []\n",
    "for i, prompt_text in enumerate(tqdm(blocks, desc=\"Generating\")):\n",
    "    try:\n",
    "        response = client.completions.create(\n",
    "            model=model_name,\n",
    "            prompt=prompt_text,\n",
    "            temperature=0.7,\n",
    "            max_tokens=256,\n",
    "        )\n",
    "        result = {\n",
    "            \"id\": i + 1,\n",
    "            \"chatml_prompt\": prompt_text,\n",
    "            \"generated_followup\": response.choices[0].text.strip()  # ✅ 修复这里\n",
    "        }\n",
    "    except Exception as e:\n",
    "        result = {\n",
    "            \"id\": i + 1,\n",
    "            \"chatml_prompt\": prompt_text,\n",
    "            \"generated_followup\": f\"[ERROR] {str(e)}\"\n",
    "        }\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "# 保存结果\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    json.dump(results, f_out, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Output saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7620b37-5961-47ce-9b70-e5e271ab43cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
